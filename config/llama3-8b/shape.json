{
    "type": "llama",
    "layer_num": 32,
    "hidden_dim": 4096,
    "intermediate_dim": 14336,
    "q_head_num": 32,
    "kv_head_num": 8
}